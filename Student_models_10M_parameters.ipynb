{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Student_models_10M_parameters.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "gL_TgAPZbQ1E",
        "WSabDwbPbW-1",
        "rVCOPh5KPWpW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbUY0jnGaSFc",
        "colab_type": "text"
      },
      "source": [
        "# STUDENT MODELS WITH 10M PARAMETERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mkM1pjOaVfj",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reivqlrUEnTE",
        "colab_type": "code",
        "outputId": "36de372b-27a3-42d0-9b13-ebdd5461428e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10,cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import Sequence\n",
        "from keras import regularizers\n",
        "from keras.models import load_model\n",
        "import os\n",
        "from keras.models import Model\n",
        "import h5py\n",
        "\n",
        "import time\n",
        "\n",
        "import colorsys #enables us to convert a rgb vector to a hsv vector\n",
        "from skimage.color import rgb2hsv, hsv2rgb\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTCyFVTGatzX",
        "colab_type": "text"
      },
      "source": [
        "### Import Dataset CIFAR_100\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVnjfFzLGmMQ",
        "colab_type": "code",
        "outputId": "9c9e4dd7-b1a0-4657-bfc0-5c4dc4079e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### LOAD CIFAR_100\n",
        "\n",
        "reset_graph()\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "\n",
        "#Define num_classes\n",
        "num_classes = 100\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B70Is5oDl2xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    Compute softmax values for each sets of scores in x.\n",
        "    \n",
        "    Rows are scores for each class. \n",
        "    Columns are predictions (samples).\n",
        "    \"\"\"\n",
        "    scoreMatExp = np.exp(np.asarray(x))\n",
        "    return scoreMatExp / scoreMatExp.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHFsB0eXWSJH",
        "colab_type": "text"
      },
      "source": [
        "## 1- Creation of the dataset using distillation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDdHyxQnXmTX",
        "outputId": "5f4e6b39-4c4d-4312-811a-462f6b81e7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "#Load the teacher model\n",
        "\n",
        "#teacher_model = load_model('keras_cifar10_trained_model2.h5')\n",
        "teacher_model = load_model('cifar_100_teacher.h5')\n",
        "\n",
        "#Get the layer just before the softmax layer\n",
        "without_softmax_model = Model(inputs=teacher_model.input, outputs=teacher_model.get_layer('dense_3').output)\n",
        "\n",
        "#Keep a copy of the original dataset before modifications\n",
        "x_train_bis = np.copy(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL_TgAPZbQ1E",
        "colab_type": "text"
      },
      "source": [
        "### Definitions of the different functions used in this ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibHSiEOT3jNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# random crop needed for training augmentation\n",
        "def random_crop(img):\n",
        "    height, width, _ = img.shape\n",
        "    dy, dx = input_size, input_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    img = img[y:(y+dy), x:(x+dx), :]\n",
        "    return img\n",
        "\n",
        "# center crop needed for testing (validation & test sets)\n",
        "def center_crop(img):\n",
        "    height, width, _ = img.shape\n",
        "    dy, dx = input_size, input_size\n",
        "    x = int((width - dx + 1)/2)\n",
        "    y = int((height - dy + 1)/2)\n",
        "    img = img[y:(y+dy), x:(x+dx), :]\n",
        "    return img\n",
        "  \n",
        " # softmax function\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    Compute softmax values for each sets of scores in x.\n",
        "    \n",
        "    Rows are scores for each class. \n",
        "    Columns are predictions (samples).\n",
        "    \"\"\"\n",
        "    scoreMatExp = np.exp(np.asarray(x))\n",
        "    return scoreMatExp / scoreMatExp.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSabDwbPbW-1",
        "colab_type": "text"
      },
      "source": [
        "### Preparation of the data for Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwxWwlS9bhQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Divide into training and validation set\n",
        "\n",
        "x_validation = x_train_bis[40000:]\n",
        "x_train_bis = x_train_bis[:40000]\n",
        "\n",
        "\n",
        "#Define input size for the data augmentation : we will keep input_size pixels after data augmentation\n",
        "input_size = 28\n",
        "\n",
        "### Cropping the images\n",
        "X_train = np.zeros((np.shape(x_train_bis)[0],input_size,input_size,3))\n",
        "\n",
        "#random crop for training set\n",
        "for i in range(np.shape(x_train_bis)[0]):\n",
        "  X_train[i] = random_crop(x_train_bis[i])\n",
        "  \n",
        "X_validation = np.zeros((np.shape(x_validation)[0],input_size,input_size,3))\n",
        "\n",
        "#center crop for validation set, no need for data augmentation, just input_size size images\n",
        "for i in range(np.shape(x_validation)[0]):\n",
        "  X_validation[i] = center_crop(x_validation[i])\n",
        "  \n",
        "### Normalizing the data\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "X_validation = X_validation.astype('float32')\n",
        "X_train /= 255\n",
        "x_test /= 255\n",
        "X_validation /= 255\n",
        "\n",
        "y_train_soft = without_softmax_model.predict(X_train, batch_size=32, verbose=0, steps=None)\n",
        "y_validation_soft = without_softmax_model.predict(X_validation, batch_size=32, verbose=0, steps=None)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "for i in range(len(y_train_soft)):\n",
        "  y_train_soft[i] = y_train_soft[i]/np.linalg.norm(y_train_soft[i])\n",
        "\n",
        "for i in range(len(y_validation_soft)):\n",
        "  y_validation_soft[i] = y_validation_soft[i]/np.linalg.norm(y_validation_soft[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN6J9cZf9FkT",
        "colab_type": "text"
      },
      "source": [
        "## 2- Creation of the student models with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zzyFIir3U8w",
        "colab_type": "text"
      },
      "source": [
        "### A- MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpXwTxyb6t0G",
        "colab_type": "text"
      },
      "source": [
        "#### One hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf8_97aj9Mn0",
        "colab_type": "code",
        "outputId": "854b1e65-1ee5-49f3-c894-f5e68c8f614f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(4000, input_shape=(28*28*3,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 4000)              9412000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4000)              16000     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               400100    \n",
            "=================================================================\n",
            "Total params: 9,828,100\n",
            "Trainable params: 9,820,100\n",
            "Non-trainable params: 8,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXGPAtsP6vsx",
        "colab_type": "text"
      },
      "source": [
        "#### Two hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOYfItz06v0b",
        "colab_type": "code",
        "outputId": "82c1f4a8-db74-45fb-e099-c05bf70a70aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(3000, input_shape=(28*28*3,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(1000))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3000)              7059000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 3000)              12000     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              3001000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               100100    \n",
            "=================================================================\n",
            "Total params: 10,176,100\n",
            "Trainable params: 10,168,100\n",
            "Non-trainable params: 8,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdRUNV906v6y",
        "colab_type": "text"
      },
      "source": [
        "#### Three hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Un08Dc6wAB",
        "colab_type": "code",
        "outputId": "1eabe87d-954c-41e3-d4f1-0edbe674ea15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2000, input_shape=(28*28*3,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(1500))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(2000))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2000)              4706000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2000)              8000      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1500)              3001500   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1500)              6000      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1500)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1500)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2000)              3002000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2000)              8000      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               200100    \n",
            "=================================================================\n",
            "Total params: 10,931,600\n",
            "Trainable params: 10,920,600\n",
            "Non-trainable params: 11,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wAJM_pw6wFD",
        "colab_type": "text"
      },
      "source": [
        "#### Four hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ndNSeDO6wKL",
        "colab_type": "code",
        "outputId": "6e468242-c78c-4037-a48f-1d8f761ed200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2000, input_shape=(28*28*3,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(1500))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(1000))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(1000))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2000)              4706000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2000)              8000      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1500)              3001500   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1500)              6000      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1500)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1500)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1000)              1501000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               100100    \n",
            "=================================================================\n",
            "Total params: 10,331,600\n",
            "Trainable params: 10,320,600\n",
            "Non-trainable params: 11,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3kg3563W4l",
        "colab_type": "text"
      },
      "source": [
        "### B- CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwBTBt-13aWS",
        "colab_type": "text"
      },
      "source": [
        "#### One convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvJ8qyTb3bWS",
        "colab_type": "code",
        "outputId": "a0776f8e-1aff-4d57-ce7d-c34dca77d920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(100, (3, 3), padding='same',\n",
        "                 input_shape=(28,28,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 100)       2800      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 100)       400       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 100)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 100)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 100)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 19600)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               9800500   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               50100     \n",
            "=================================================================\n",
            "Total params: 9,855,800\n",
            "Trainable params: 9,854,600\n",
            "Non-trainable params: 1,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm_aEKZq3bje",
        "colab_type": "text"
      },
      "source": [
        "#### Two convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI5hVmgA3bzq",
        "colab_type": "code",
        "outputId": "31a9533c-0361-42eb-8dda-9a2797095d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(300, (3, 3), padding='same',\n",
        "                 input_shape=(28,28,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(120, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1600))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 300)       8400      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 300)       1200      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 300)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 300)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 300)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 120)       324120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 120)       480       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 120)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 120)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 120)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5880)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1600)              9409600   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1600)              6400      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               160100    \n",
            "=================================================================\n",
            "Total params: 9,910,300\n",
            "Trainable params: 9,906,260\n",
            "Non-trainable params: 4,040\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ramji5-M3cBi",
        "colab_type": "text"
      },
      "source": [
        "#### Three convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mxTWUOX3cLE",
        "colab_type": "code",
        "outputId": "6c8d5d5e-7bb4-4a54-b721-cf97130358e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(350, (3, 3), padding='same',\n",
        "                 input_shape=(28,28,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(350, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(350, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2500))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 350)       9800      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 350)       1400      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 350)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 350)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 350)       1102850   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 350)       1400      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 350)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 350)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 350)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 350)         1102850   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 350)         1400      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 350)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 350)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 350)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3150)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2500)              7877500   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2500)              10000     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2500)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2500)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               250100    \n",
            "=================================================================\n",
            "Total params: 10,357,300\n",
            "Trainable params: 10,350,200\n",
            "Non-trainable params: 7,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JgMIJsi3cj7",
        "colab_type": "text"
      },
      "source": [
        "#### Four convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz_IYoaHx5CC",
        "colab_type": "code",
        "outputId": "a421ffbb-4091-4bb4-d0ee-5a73a4231e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(325, (3, 3), padding='same',\n",
        "                 input_shape=(28,28,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(325, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(375, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(375, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2000))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 325)       9100      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 325)       1300      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 325)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 325)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 325)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 325)       950950    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 325)       1300      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 325)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 325)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 325)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 375)         1097250   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 375)         1500      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 375)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 375)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 3, 3, 375)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 375)         1266000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 3, 3, 375)         1500      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 3, 3, 375)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 3, 375)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3375)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2000)              6752000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2000)              8000      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               200100    \n",
            "=================================================================\n",
            "Total params: 10,289,000\n",
            "Trainable params: 10,282,200\n",
            "Non-trainable params: 6,800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCOPh5KPWpW",
        "colab_type": "text"
      },
      "source": [
        "#### Test CNN : not used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYU9s9FjPYJv",
        "colab_type": "code",
        "outputId": "ac736c0a-a04a-4e98-a217-04f3d4f5fc92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "source": [
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(28,28,3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(350))\n",
        "model.add(Dense(num_classes))\n",
        " \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 350)               403550    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               35100     \n",
            "=================================================================\n",
            "Total params: 727,450\n",
            "Trainable params: 726,554\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rkl4GDn9Iin",
        "colab_type": "text"
      },
      "source": [
        "## 3- Training the chosen student model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDQdIrCc3d2b",
        "colab_type": "code",
        "outputId": "202d4006-fbbb-4ac7-c155-56c95d7df2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1109
        }
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 30\n",
        "data_augmentation = True #write False for a MLP and True for a CNN\n",
        "\n",
        "#opt = keras.optimizers.rmsprop(lr=0.1, decay=1e-6)\n",
        "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=opt)\n",
        "\n",
        "\n",
        "if data_augmentation == True:\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "          horizontal_flip=True  # randomly flip images\n",
        "  )\n",
        "\n",
        "  validation_and_test_datagen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "      # Batch generators\n",
        "  train_generator = train_datagen.flow(\n",
        "      X_train, \n",
        "      y_train_soft,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  validation_generator = validation_and_test_datagen.flow(\n",
        "      X_validation, \n",
        "      y_validation_soft, \n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "\n",
        "      # this class is needed to adapt keras pipeline to shape modifications\n",
        "  class crop_gen(Sequence):\n",
        "\n",
        "      def __init__(self, gen):\n",
        "          self.gen = gen\n",
        "          self.x, self.y = next(gen)\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "      def __len__(self):\n",
        "          return self.gen.__len__()\n",
        "\n",
        "      def __getitem__(self, idx):\n",
        "          batch_x, batch_y = next(self.gen)\n",
        "          batch_crops = np.zeros((batch_x.shape[0], input_size, input_size, 3))\n",
        "          for i in range(batch_x.shape[0]):\n",
        "              batch_crops[i] = random_crop(batch_x[i])\n",
        "          return batch_crops, batch_y\n",
        "\n",
        "  # this class is needed to adapt keras pipeline to shape modifications    \n",
        "  class crop_gen_center(Sequence):\n",
        "\n",
        "      def __init__(self, gen):\n",
        "          self.gen = gen\n",
        "          self.x, self.y = gen.__getitem__(0)\n",
        "          self.batch_size = batch_size\n",
        "          #self.classes = gen.classes\n",
        "          self.class_indices = np.arange(num_classes) #gen.class_indices\n",
        "\n",
        "      def __len__(self):\n",
        "          return self.gen.__len__()\n",
        "\n",
        "\n",
        "      def __getitem__(self, idx):\n",
        "          batch_x, batch_y = next(self.gen)\n",
        "          batch_crops = np.zeros((batch_x.shape[0], input_size, input_size, 3))\n",
        "          for i in range(batch_x.shape[0]):\n",
        "              batch_crops[i] = center_crop(batch_x[i])\n",
        "          return batch_crops, batch_y\n",
        "\n",
        "  #train_generator = crop_gen(train_generator)\n",
        "  #validation_generator = crop_gen_center(validation_generator)\n",
        "\n",
        "  # Fit the model on the batches generated by datagen.flow().\n",
        "  print('x_train shape:', X_train.shape)\n",
        "  print('x_validation shape:', X_validation.shape)\n",
        "  history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    shuffle=True,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps = len(X_validation)/batch_size,\n",
        "    steps_per_epoch = len(X_train)/batch_size,\n",
        "    workers=4\n",
        "  )\n",
        "else:\n",
        "  for i in range(len(X_train)):\n",
        "    if np.random.uniform(0,1) > 0.5:\n",
        "      X_train[i] = np.flip(X_train[i],axis=1)\n",
        "      \n",
        "  X_train = X_train.reshape(40000,28*28*3)\n",
        "  X_validation = X_validation.reshape(10000,28*28*3)\n",
        "\n",
        "  history = model.fit(X_train, y_train_soft,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      verbose=1,\n",
        "                      validation_data=(X_validation, y_validation_soft))\n",
        "    \n",
        "# Save model and weights\n",
        "#if not os.path.isdir(save_dir):\n",
        "#    os.makedirs(save_dir)\n",
        "#model_path = os.path.join(save_dir, model_name)\n",
        "#model.save(model_path)\n",
        "#print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "\n",
        "X_test = np.zeros((np.shape(x_test)[0],input_size,input_size,3))\n",
        "\n",
        "for i in range(np.shape(x_test)[0]):\n",
        "  X_test[i] = center_crop(x_test[i])\n",
        "  \n",
        "if data_augmentation==False:\n",
        "  X_test = X_test.reshape(10000,28*28*3)\n",
        "  \n",
        "  # Score trained model.\n",
        "scores = model.evaluate(X_test, y_test_cat, verbose=1)\n",
        "print('Test loss:', scores)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "acc = 0\n",
        "softmax_predictions = np.zeros((num_classes,10000))\n",
        "for i in range(np.shape(X_test)[0]):\n",
        "  softmax_predictions[:,i] = softmax(predictions[i,:])\n",
        "  if np.argmax(softmax_predictions[:,i])==y_test[i]:\n",
        "    acc = acc + 1\n",
        "acc = acc/10000\n",
        "\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (40000, 28, 28, 3)\n",
            "x_validation shape: (10000, 28, 28, 3)\n",
            "Epoch 1/30\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 0.0618 - val_loss: 0.0012\n",
            "Epoch 2/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 0.0024 - val_loss: 6.4366e-04\n",
            "Epoch 3/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 0.0010 - val_loss: 5.7260e-04\n",
            "Epoch 4/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 7.5885e-04 - val_loss: 6.1131e-04\n",
            "Epoch 5/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 6.0924e-04 - val_loss: 4.9698e-04\n",
            "Epoch 6/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 5.1966e-04 - val_loss: 4.5689e-04\n",
            "Epoch 7/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 4.5862e-04 - val_loss: 4.2215e-04\n",
            "Epoch 8/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 4.2739e-04 - val_loss: 3.9120e-04\n",
            "Epoch 9/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 4.1307e-04 - val_loss: 0.0044\n",
            "Epoch 10/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 4.0504e-04 - val_loss: 3.4464e-04\n",
            "Epoch 11/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 3.7671e-04 - val_loss: 3.3620e-04\n",
            "Epoch 12/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 3.6384e-04 - val_loss: 3.6492e-04\n",
            "Epoch 13/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 3.4970e-04 - val_loss: 3.4241e-04\n",
            "Epoch 14/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 3.4042e-04 - val_loss: 3.0653e-04\n",
            "Epoch 15/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 3.2750e-04 - val_loss: 2.7380e-04\n",
            "Epoch 16/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 3.1655e-04 - val_loss: 2.7497e-04\n",
            "Epoch 17/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 3.1197e-04 - val_loss: 2.7426e-04\n",
            "Epoch 18/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 3.0171e-04 - val_loss: 2.6850e-04\n",
            "Epoch 19/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 2.9550e-04 - val_loss: 2.9062e-04\n",
            "Epoch 20/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 6.6736e-04 - val_loss: 4.9572e-04\n",
            "Epoch 21/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 4.8418e-04 - val_loss: 3.9749e-04\n",
            "Epoch 22/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 4.1252e-04 - val_loss: 3.1555e-04\n",
            "Epoch 23/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 3.6230e-04 - val_loss: 2.8417e-04\n",
            "Epoch 24/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 3.3286e-04 - val_loss: 2.6860e-04\n",
            "Epoch 25/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 3.1465e-04 - val_loss: 2.4783e-04\n",
            "Epoch 26/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 3.0394e-04 - val_loss: 2.6285e-04\n",
            "Epoch 27/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 2.9712e-04 - val_loss: 2.3431e-04\n",
            "Epoch 28/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 2.9130e-04 - val_loss: 2.2596e-04\n",
            "Epoch 29/30\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 2.8474e-04 - val_loss: 2.3754e-04\n",
            "Epoch 30/30\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 2.8257e-04 - val_loss: 2.9262e-04\n",
            "10000/10000 [==============================] - 2s 200us/step\n",
            "Test loss: 0.020762510278820992\n",
            "Test accuracy: 0.2937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNMrKT_5cYFz",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the loss curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIDTx3DECoj-",
        "colab_type": "code",
        "outputId": "ed20fab9-9584-4a77-f083-f7249edaba67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# list all data in historys\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJlZQw4LMzNr6P8DsPEdxxktYroAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsfY4PDrcapZ",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the different models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK1T_x5HM6h8",
        "colab_type": "code",
        "outputId": "e96d2ecc-da84-4da6-c3e1-681f84d7e6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot([1,1,1,1,1,1,1,1,],[0.67,0.7481,0.7432,0.7596,0.4302,0.4751,0.4992,0.4725],marker='o')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff9f547fa58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFBhJREFUeJzt3W+MHPd93/H3xyfKZhGnpMNLYfGP\nSKcUY7cKRPsq2BGcCAIkEn0gqTHgMilQKUDMFinjJoFZkCggB9SDqiXapEUExGpKIAlgU62iEmeE\nKUNEVV3IkssTSIshBUoU3Vh3MmpGFFMYvpoU9e2DHcrLM6ndu1ve3nHeL2BwO9/5zd73xz+fmZud\n3UtVIUlqh/cNuwFJ0sIx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNfklrE0JekFrlp2A3M\ntGrVqlq/fv2w25CkJeXFF1/8q6oa7TVu0YX++vXrmZiYGHYbkrSkJPnLfsZ5eUeSWsTQl6QWMfQl\nqUUMfUlqEUNfklpk0d29Iy1GB45OsffQKd44P80tK5azc8smHty8ethtSbNm6Es9HDg6xe6njzN9\n8RIAU+en2f30cQCDX0uOl3ekHvYeOvVu4F82ffESew+dGlJH0twZ+lIPb5yfnlVdWswMfamHW1Ys\nn1VdWsz6Cv0kW5OcSnI6ya6rbP/tJMea5ZUk57u2XeraNj7I5qWFsHPLJpYvG7mitnzZCDu3bBpS\nR9Lc9XwhN8kI8DhwLzAJHEkyXlUnL4+pqt/oGv9rwOaup5iuqjsG17K0sC6/WPvrTx4DYLV372gJ\n6+dM/07gdFWdqaoLwH7ggfcY/4vAVwbRnCRpsPoJ/dXA613rk03tRyS5FdgAPNNV/kCSiSQvJHlw\nzp1KQ3L5ls3LLt+yeeDo1BC7kuZm0C/kbgOeqqru+9turaox4JeA30nyUzN3SrK9OTBMnD17dsAt\nSfPjLZu6kfQT+lPA2q71NU3tarYx49JOVU01X88Az3Ll9f7LY56oqrGqGhsd7fk7AKQF5S2bupH0\nE/pHgI1JNiS5mU6w/8hdOEl+GlgJPN9VW5nk/c3jVcBdwMmZ+0qL2d9cvmxWdWkx63n3TlW9nWQH\ncAgYAfZV1Ykke4CJqrp8ANgG7K+q6tr9o8CXkrxD5wDzWPddP9JSkMyuLi1mfX32TlUdBA7OqD0y\nY/23rrLf14Hb59GfNHTnv39xVnVpMfMduVIPviNXNxJDX+rBd+TqRuJHK0s9+I5c3Ug805f60B3w\nz+26x8DXkmXoS1KLGPqS1CKGviS1iKEvSS1i6EtSixj6ktQihr4ktYihL0ktYuhLUosY+pLUIoa+\nJLWIoS9JLWLoS1KLGPqS1CKGviS1iKEvSS1i6EtSi/QV+km2JjmV5HSSXVfZ/ttJjjXLK0nOd217\nKMmrzfLQIJuXJM1Oz9+Rm2QEeBy4F5gEjiQZr6qTl8dU1W90jf81YHPz+EPAF4ExoIAXm33fGugs\nJEl96edM/07gdFWdqaoLwH7ggfcY/4vAV5rHW4DDVXWuCfrDwNb5NCxJmrt+Qn818HrX+mRT+xFJ\nbgU2AM/Mdl9J0vU36BdytwFPVdWl2eyUZHuSiSQTZ8+eHXBLkqTL+gn9KWBt1/qapnY12/jhpZ2+\n962qJ6pqrKrGRkdH+2hJkjQX/YT+EWBjkg1JbqYT7OMzByX5aWAl8HxX+RBwX5KVSVYC9zU1SdIQ\n9Lx7p6reTrKDTliPAPuq6kSSPcBEVV0+AGwD9ldVde17LsmjdA4cAHuq6txgpyBJ6lfP0AeoqoPA\nwRm1R2as/9Y19t0H7Jtjf5KkAfIduZLUIoa+JLWIoS9JLWLoS1KLGPqS1CKGviS1iKEvSS1i6EtS\nixj6ktQihr4ktYihL/XhwNEffjjsXY89c8W6tJQY+lIPB45Osfvp4++uT52fZvfTxw1+LUmGvtTD\n3kOnmL545e8Fmr54ib2HTg2pI2nuDH2phzfOT8+qLi1mhr7Uwy0rls+qLi1mhr7Uw84tm1i+bOSK\n2vJlI+zcsmlIHUlz19cvUZHa7MHNqwH4F0+9xIVL77B6xXJ2btn0bl1aSgx9qQ8Pbl7NV/7XtwF4\n8p98asjdSHPn5R1JahFDX5JaxNCXpBbpK/STbE1yKsnpJLuuMeazSU4mOZHky131S0mONcv4oBqX\nJM1ezxdyk4wAjwP3ApPAkSTjVXWya8xGYDdwV1W9leQnu55iuqruGHDfkqQ56OdM/07gdFWdqaoL\nwH7ggRljPgc8XlVvAVTVdwfbpiRpEPoJ/dXA613rk02t223AbUmeS/JCkq1d2z6QZKKpPzjPfiVJ\n8zCo+/RvAjYCdwNrgK8lub2qzgO3VtVUko8AzyQ5XlWvde+cZDuwHWDdunUDakmSNFM/Z/pTwNqu\n9TVNrdskMF5VF6vqW8ArdA4CVNVU8/UM8CyweeY3qKonqmqsqsZGR0dnPQlJUn/6Cf0jwMYkG5Lc\nDGwDZt6Fc4DOWT5JVtG53HMmycok7++q3wWcRJI0FD0v71TV20l2AIeAEWBfVZ1IsgeYqKrxZtt9\nSU4Cl4CdVfVmkp8FvpTkHToHmMe67/qRJC2svq7pV9VB4OCM2iNdjwv4zWbpHvN14Pb5tylJGgTf\nkStJLWLoS1KLGPqS1CKGviS1iKEvSS1i6EtSixj6ktQihr4ktYihL0ktYuhLUosY+pLUIoa+JLWI\noS9JLWLoS1KLGPqS1CKGviS1iKEvSS1i6EtSixj6ktQihr4ktYihL0kt0lfoJ9ma5FSS00l2XWPM\nZ5OcTHIiyZe76g8lebVZHhpU45Kk2bup14AkI8DjwL3AJHAkyXhVnewasxHYDdxVVW8l+cmm/iHg\ni8AYUMCLzb5vDX4qkqRe+jnTvxM4XVVnquoCsB94YMaYzwGPXw7zqvpuU98CHK6qc822w8DWwbQu\nSZqtfkJ/NfB61/pkU+t2G3BbkueSvJBk6yz2lSQtkJ6Xd2bxPBuBu4E1wNeS3N7vzkm2A9sB1q1b\nN6CWJEkz9XOmPwWs7Vpf09S6TQLjVXWxqr4FvELnINDPvlTVE1U1VlVjo6Ojs+lfkjQL/YT+EWBj\nkg1Jbga2AeMzxhygc5ZPklV0LvecAQ4B9yVZmWQlcF9TkyQNQc/LO1X1dpIddMJ6BNhXVSeS7AEm\nqmqcH4b7SeASsLOq3gRI8iidAwfAnqo6dz0mIknqra9r+lV1EDg4o/ZI1+MCfrNZZu67D9g3vzYl\nSYPgO3IlqUUMfUlqEUNfklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQ\nl6QWMfQlqUUMfUlqEUNfklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRfoK/SRbk5xKcjrJ\nrqtsfzjJ2STHmuVXurZd6qqPD7J5SdLs3NRrQJIR4HHgXmASOJJkvKpOzhj6ZFXtuMpTTFfVHfNv\nVZI0X/2c6d8JnK6qM1V1AdgPPHB925IkXQ/9hP5q4PWu9cmmNtNnkryU5Kkka7vqH0gykeSFJA/O\np1lJ0vwM6oXcrwLrq+pngMPAH3Rtu7WqxoBfAn4nyU/N3DnJ9ubAMHH27NkBtSRJmqmf0J8Cus/c\n1zS1d1XVm1X1g2b194FPdG2bar6eAZ4FNs/8BlX1RFWNVdXY6OjorCYgSepfP6F/BNiYZEOSm4Ft\nwBV34ST5cNfq/cDLTX1lkvc3j1cBdwEzXwCWJC2QnnfvVNXbSXYAh4ARYF9VnUiyB5ioqnHg80nu\nB94GzgEPN7t/FPhSknfoHGAeu8pdP5KkBdIz9AGq6iBwcEbtka7Hu4HdV9nv68Dt8+xRkjQgviNX\nklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNf\nklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWqSv0E+yNcmpJKeT7LrK9oeT\nnE1yrFl+pWvbQ0lebZaHBtm8JGl2buo1IMkI8DhwLzAJHEkyXlUnZwx9sqp2zNj3Q8AXgTGggBeb\nfd8aSPeSpFnp50z/TuB0VZ2pqgvAfuCBPp9/C3C4qs41QX8Y2Dq3VqXhOXB0iqPfPs83vnWOux57\nhgNHp4bdkjQn/YT+auD1rvXJpjbTZ5K8lOSpJGtnua+0aB04OsXup49z4dI7AEydn2b308cNfi1J\ng3oh96vA+qr6GTpn838wm52TbE8ykWTi7NmzA2pJGoy9h04xffHSFbXpi5fYe+jUkDqS5q6f0J8C\n1natr2lq76qqN6vqB83q7wOf6HffZv8nqmqsqsZGR0f77V1aEG+cn55VXVrM+gn9I8DGJBuS3Axs\nA8a7ByT5cNfq/cDLzeNDwH1JViZZCdzX1KQl45YVy2dVlxaznqFfVW8DO+iE9cvAf66qE0n2JLm/\nGfb5JCeSfBP4PPBws+854FE6B44jwJ6mJi0ZO7dsYvmykStqy5eNsHPLpiF1JM1dqmrYPVxhbGys\nJiYmht2GdIUDR6f49SePAbB6xXJ2btnEg5u9J0GLR5IXq2qs1zjfkSv1oTvgn9t1j4GvJcvQl6QW\nMfQlqUUMfUlqEUNfklrE0JekFjH0JalFDH2pD90fruanbGopM/SlHi5/yuZlfsqmljJDX+rBT9nU\njcTQl3qYusanaV6rLi1mhr7Uw0gyq7q0mBn6Ug+XrvGhhNeqS4uZoS/1sPoan5t/rbq0mBn6Ug9+\nnr5uJDcNuwFpsbv8Mcp+nr5uBJ7pS33w8/R1ozD0JalFDH1JahFDX5JaxNCXpBbpK/STbE1yKsnp\nJLveY9xnklSSsWZ9fZLpJMea5fcG1bgkafZ63rKZZAR4HLgXmASOJBmvqpMzxn0Q+OfAN2Y8xWtV\ndceA+pUkzUM/Z/p3Aqer6kxVXQD2Aw9cZdyjwL8G/t8A+5MkDVA/ob8aeL1rfbKpvSvJx4G1VfUn\nV9l/Q5KjSf5Hkk/PvVVJ0nzN+x25Sd4H/Dvg4ats/g6wrqreTPIJ4ECSv1NV/3fGc2wHtgOsW7du\nvi1Jkq6hnzP9KWBt1/qapnbZB4G/Czyb5H8DnwTGk4xV1Q+q6k2AqnoReA24beY3qKonqmqsqsZG\nR0fnNhNJUk/9hP4RYGOSDUluBrYB45c3VtVfV9WqqlpfVeuBF4D7q2oiyWjzQjBJPgJsBM4MfBaS\npL70vLxTVW8n2QEcAkaAfVV1IskeYKKqxt9j958D9iS5CLwD/NOqOjeIxiVJs9fXNf2qOggcnFF7\n5Bpj7+56/MfAH8+jP0nSAPmOXElqEUNfklrE0JekFjH0JalFDH2pDweO/vCtKXc99swV69JSYuhL\nPRw4OsXup4+/uz51fprdTx83+LUkGfpSD3sPnWL64qUratMXL7H30KkhdSTNnaEv9fDG+elZ1aXF\nzNCXerhlxfJZ1aXFzNCXeti5ZRPLl41cUVu+bISdWzYNqSNp7ub90crSje7BzZ1fH7H30CneOD/N\nLSuWs3PLpnfr0lJi6Et9eHDzakNeNwQv70hSixj6ktQihr4ktYihL0ktYuhLUoukqobdwxWSnAX+\ncth9zMEq4K+G3cQCc87t4JyXhlurarTXoEUX+ktVkomqGht2HwvJObeDc76xeHlHklrE0JekFjH0\nB+eJYTcwBM65HZzzDcRr+pLUIp7pS1KLGPp9SLI1yakkp5Psusr2W5P8eZKXkjybZE3XtnVJ/izJ\ny0lOJlm/kL3P1Tzn/G+SnGjm/B+SZGG7n70k+5J8N8lfXGN7mrmcbub88a5tDyV5tVkeWriu52eu\nc05yR5Lnm7/jl5L8w4XtfO7m8/fcbP/xJJNJfndhOr4OqsrlPRZgBHgN+AhwM/BN4GMzxvwX4KHm\n8T3AH3Vtexa4t3n8Y8DfGPacruecgZ8FnmueYwR4Hrh72HPqY84/B3wc+ItrbP/7wJ8CAT4JfKOp\nfwg403xd2TxeOez5XOc53wZsbB7fAnwHWDHs+VzPOXdt//fAl4HfHfZc5rp4pt/bncDpqjpTVReA\n/cADM8Z8DHimefzfL29P8jHgpqo6DFBV36uq7y9M2/My5zkDBXyAzsHi/cAy4P9c947nqaq+Bpx7\njyEPAH9YHS8AK5J8GNgCHK6qc1X1FnAY2Hr9O56/uc65ql6pqleb53gD+C7Q801Bi8E8/p5J8gng\nbwF/dv07vX4M/d5WA693rU82tW7fBH6hefwPgA8m+Qk6Z0Tnkzyd5GiSvUlGWPzmPOeqep7OQeA7\nzXKoql6+zv0uhGv9mfTzZ7VU9ZxbkjvpHOBfW8C+rqerzjnJ+4B/C3xhKF0NkKE/GF8Afj7JUeDn\ngSngEp1fUvPpZvvfo3O55OEh9ThoV51zkr8NfBRYQ+c/0D1JPj28NnW9NGfAfwT8clW9M+x+rrNf\nBQ5W1eSwG5kvf3NWb1PA2q71NU3tXc2PuL8AkOTHgM9U1fkkk8CxqjrTbDtA5zrhf1qIxudhPnP+\nHPBCVX2v2fanwKeA/7kQjV9H1/ozmQLunlF/dsG6ur6u+e8gyY8DfwL8y+YyyI3iWnP+FPDpJL9K\n57W5m5N8r6p+5CaHxc4z/d6OABuTbEhyM7ANGO8ekGRV8+MfwG5gX9e+K5Jcvt55D3ByAXqer/nM\n+dt0fgK4KckyOj8F3AiXd8aBf9zc3fFJ4K+r6jvAIeC+JCuTrATua2o3gqvOufk38V/pXPt+argt\nDtxV51xV/6iq1lXVejo/5f7hUgx88Ey/p6p6O8kOOv+RR4B9VXUiyR5goqrG6Zzp/askBXwN+GfN\nvpeSfAH48+a2xReB/ziMeczGfOYMPEXn4Haczou6/62qvrrQc5itJF+hM6dVzU9oX6TzIjRV9XvA\nQTp3dpwGvg/8crPtXJJH6RwoAfZU1Xu9ULhozHXOwGfp3AXzE0kebmoPV9WxBWt+juYx5xuG78iV\npBbx8o4ktYihL0ktYuhLUosY+pLUIoa+JLWIoS9JLWLoS1KLGPqS1CL/H0yfO5kiEe2EAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}