{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Teacher_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "-QUGZm3dfQZt",
        "ZV76e73nfSmN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRHTn3vLdrhy",
        "colab_type": "text"
      },
      "source": [
        "# TEACHER MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lUdmlkZdxXF",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yXZ9msx_RS-",
        "colab_type": "code",
        "outputId": "cff65596-13fc-4681-a50b-4702dd11214e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar100, cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import Sequence\n",
        "from keras import regularizers\n",
        "import os\n",
        "\n",
        "import time\n",
        "import h5py\n",
        "\n",
        "import colorsys #enables us to convert a rgb vector to a hsv vector\n",
        "from skimage.color import rgb2hsv, hsv2rgb\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "import cv2\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyW9sY8IJOBN",
        "colab_type": "text"
      },
      "source": [
        "### Import Dataset : choose between CIFAR_10 and CIFAR_100\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNCSZ4saIgrK",
        "colab_type": "code",
        "outputId": "ea4019e0-28a3-4f5b-8c38-05524fcf9b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Loading the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "#(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "\n",
        "\n",
        "#Define the number of classes that you want to use\n",
        "\n",
        "num_classes = 10\n",
        "#num_classes = 100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 101s 1us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXhsVFRSeZVZ",
        "colab_type": "text"
      },
      "source": [
        "## 1- Creation of the dataset to build the distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSOLhotfegx_",
        "colab_type": "text"
      },
      "source": [
        "### Definitions of the different functions used in this ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeFc_J2yel9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# random crop needed for training augmentation\n",
        "def random_crop(img):\n",
        "    height, width, _ = img.shape\n",
        "    dy, dx = input_size, input_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    img = img[y:(y+dy), x:(x+dx), :]\n",
        "    return img\n",
        "\n",
        "# center crop needed for testing (validation & test sets)\n",
        "def center_crop(img):\n",
        "    height, width, _ = img.shape\n",
        "    dy, dx = input_size, input_size\n",
        "    x = int((width - dx + 1)/2)\n",
        "    y = int((height - dy + 1)/2)\n",
        "    img = img[y:(y+dy), x:(x+dx), :]\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ele7Kc9rerk6",
        "colab_type": "text"
      },
      "source": [
        "### Preparation of the data for Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6vofwP3Igt2",
        "colab_type": "code",
        "outputId": "dc5993c5-7d7a-4e5d-bed5-0abc09ca85a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Divide into training and validation set\n",
        "\n",
        "x_validation = x_train_bis[40000:]\n",
        "x_train_bis = x_train_bis[:40000]\n",
        "\n",
        "\n",
        "#Define input size for the data augmentation : we will keep input_size pixels after data augmentation\n",
        "input_size = 28\n",
        "\n",
        "### Cropping the images\n",
        "X_train = np.zeros((np.shape(x_train_bis)[0],input_size,input_size,3))\n",
        "\n",
        "#random crop for training set\n",
        "for i in range(np.shape(x_train_bis)[0]):\n",
        "  X_train[i] = random_crop(x_train_bis[i])\n",
        "  \n",
        "X_validation = np.zeros((np.shape(x_validation)[0],input_size,input_size,3))\n",
        "\n",
        "#center crop for validation set, no need for data augmentation, just input_size size images\n",
        "for i in range(np.shape(x_validation)[0]):\n",
        "  X_validation[i] = center_crop(x_validation[i])\n",
        "  \n",
        "### Normalizing the data\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "X_validation = X_validation.astype('float32')\n",
        "X_train /= 255\n",
        "x_test /= 255\n",
        "X_validation /= 255\n",
        "\n",
        "y_train_soft = without_softmax_model.predict(X_train, batch_size=32, verbose=0, steps=None)\n",
        "y_validation_soft = without_softmax_model.predict(X_validation, batch_size=32, verbose=0, steps=None)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_validation shape: (10000, 32, 32, 3)\n",
            "y_validation shape: (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdHRu10he9G9",
        "colab_type": "text"
      },
      "source": [
        "## 2-Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QUGZm3dfQZt",
        "colab_type": "text"
      },
      "source": [
        "#### First version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhM-qVHKfCWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parameters of Data Augmentation\n",
        "Dh = 0.06\n",
        "Ds = 0.26\n",
        "Dv = 0.20\n",
        "As = 0.21\n",
        "Av = 0.13\n",
        "\n",
        "augmented_x_train = []\n",
        "\n",
        "#Needed for Data Augmentation, we want to convert one image in rgb to hsv scale\n",
        "def image_rgb_to_hsv(image_rgb): #We need to put a sample of image (32,32,3)\n",
        "  nb_line = np.shape(image_rgb)[0]\n",
        "  hsv_image = np.zeros((nb_line,nb_line,3))\n",
        "  \n",
        "  #Substracting the mean of the image and dividing by the standard deviation\n",
        "  image_rgb = image_rgb - np.mean(image_rgb) #So far we compute the mean of the whole image, rather than doing it separately for each channel RGB\n",
        "  image_rgb = image_rgb/np.std(image_rgb) #Same thing\n",
        "  \n",
        "  #Creating random values from an uniform distribution\n",
        "  #Shifting values\n",
        "  delta_h = np.random.uniform(-Dh,Dh)\n",
        "  delta_s = np.random.uniform(-Ds,Ds)\n",
        "  delta_v = np.random.uniform(-Dv,Dv)\n",
        "\n",
        "  #Scaling values\n",
        "  a_s = np.random.uniform(1/(1+As),1+As)\n",
        "  a_v = np.random.uniform(1/(1+Av),1+Av)\n",
        "  \n",
        "  \n",
        "  for i in range(nb_line):\n",
        "    for j in range(nb_line):\n",
        "      \n",
        "      hsv_image[i,j,:] = colorsys.rgb_to_hsv(image_rgb[i,j,0],image_rgb[i,j,1],image_rgb[i,j,2])\n",
        "      \n",
        "  #Scaling and shifting the values\n",
        "  hsv_image[:,:,0] += delta_h\n",
        "  hsv_image[:,:,1] = hsv_image[:,:,1]/a_s+delta_s\n",
        "  hsv_image[:,:,2] = hsv_image[:,:,2]/a_v+delta_v\n",
        "  \n",
        "  #Left-right symmetry of the image with a probability of 0.5\n",
        "  if np.random.uniform(0,1) > 0.5:\n",
        "    hsv_image = np.flip(hsv_image,axis=1)\n",
        "  \n",
        "  #Cropping the image\n",
        "  S = np.random.randint(24, 32)\n",
        "  x = np.random.randint(0, 32-S)\n",
        "  y = np.random.randint(0, 32-S)\n",
        "  \n",
        "  #Resizing back to 32x32\n",
        "  \n",
        "  hsv_image = hsv_image[x:x+S, y:y+S, :]\n",
        "  hsv_image = cv2.resize(hsv_image, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "      \n",
        "  return hsv_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV76e73nfSmN",
        "colab_type": "text"
      },
      "source": [
        "#### Second version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7dFLF1fVpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parameters of Data Augmentation\n",
        "#Dh = 0.02\n",
        "#Ds = 0.02\n",
        "#Dv = 0.02\n",
        "#As = 0.02\n",
        "#Av = 0.02\n",
        "\n",
        "#Needed for Data Augmentation, we want to convert one image in rgb to hsv scale\n",
        "def image_rgb_to_hsv2(img_rgb): #We need to put a sample of image (32,32,3) in [0,1]\n",
        "    #Creating random values from an uniform distribution\n",
        "    \n",
        "    # Shifting values\n",
        "    delta_h = np.random.uniform(-Dh,Dh)\n",
        "    delta_s = np.random.uniform(-Ds,Ds)\n",
        "    delta_v = np.random.uniform(-Dv,Dv)\n",
        "    \n",
        "    # Scaling values\n",
        "    a_s = np.random.uniform(1-As,1+As)\n",
        "    a_v = np.random.uniform(1-Av,1+Av)\n",
        "    \n",
        "    # normalization & color space conversion\n",
        "    # img_rgb = np.clip((img_rgb - img_rgb.mean())/img_rgb.std(),0,1)\n",
        "    img_hsv = rgb2hsv(img_rgb)\n",
        "    \n",
        "    # Scaling and shifting the values\n",
        "    img_hsv[:,:,0] = (img_hsv[:,:,0] + delta_h) % 1\n",
        "    img_hsv[:,:,1] = img_hsv[:,:,1]/a_s+delta_s\n",
        "    img_hsv[:,:,2] = img_hsv[:,:,2]/a_v+delta_v\n",
        "    img_hsv = np.clip(img_hsv, 0, 1)\n",
        "\n",
        "    # Left-right symmetry of the image with a probability of 0.5\n",
        "    if np.random.uniform(0,1) > 0.5:\n",
        "        img_hsv = np.flip(img_hsv,axis=1)\n",
        "\n",
        "    #Cropping the image\n",
        "    #S = np.random.randint(24, 32)\n",
        "    S = 28\n",
        "    x = np.random.randint(0, 32-S)\n",
        "    y = np.random.randint(0, 32-S)\n",
        "\n",
        "    #Resizing back to 32x32\n",
        "    img_hsv = img_hsv[x:x+S, y:y+S, :]\n",
        "    img_hsv = resize(img_hsv, (32, 32))\n",
        "\n",
        "    return hsv2rgb(img_hsv)\n",
        "\n",
        "img = x_train[0]/255\n",
        "new = image_rgb_to_hsv2(x_train[0]/255)\n",
        "print(\"Input image pixel range : {}, {}\".format(img.min(), img.max()))\n",
        "print(\"Output image pixel range : {}, {}\".format(new.min(), new.max()))\n",
        "plt.figure(figsize=(9,4))\n",
        "plt.subplot(121)\n",
        "plt.imshow(img)\n",
        "plt.subplot(122)\n",
        "plt.imshow(new)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlnWuMm83JEp",
        "colab_type": "text"
      },
      "source": [
        "## 3- Train the teacher model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRWEbdENhG4F",
        "colab_type": "text"
      },
      "source": [
        "#### LOAD DATA AND DEFINE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7l12xicfzXF",
        "colab_type": "code",
        "outputId": "7f17845a-cfcc-4c4b-f771-b947841ca964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1737
        }
      },
      "source": [
        "reset_graph(seed=42)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "### PARAMETERS\n",
        "\n",
        "batch_size = 32 \n",
        "epochs = 100\n",
        "num_classes = 100\n",
        "input_size = 28\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "\n",
        "### SAVE THE MODEL\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar_100_teacher.h5'\n",
        "\n",
        "\n",
        "### LOAD THE DATA\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "x_validation = x_train[40000:]\n",
        "x_train = x_train[:40000]\n",
        "print('x_validation shape:', x_validation.shape)\n",
        "\n",
        "y_validation = y_train[40000:]\n",
        "y_train = y_train[:40000]\n",
        "print('y_validation shape:', y_validation.shape)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "y_validation = keras.utils.to_categorical(y_validation, num_classes)\n",
        "\n",
        "### CHOOSE THE MODEL\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(76, (3, 3), padding='same',input_shape=(input_size,input_size,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(76, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Conv2D(126, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(126, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Conv2D(148, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(148, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(148, (3, 3), padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(148, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.37))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1200))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.42))\n",
        "model.add(Dense(1200))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.42))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_validation shape: (10000, 32, 32, 3)\n",
            "y_validation shape: (10000, 1)\n",
            "x_train shape: (40000, 32, 32, 3)\n",
            "40000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 76)        2128      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 76)        304       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 76)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 76)        52060     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 76)        304       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 76)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 76)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 76)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 126)       86310     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 126)       504       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 14, 14, 126)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 126)       143010    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 14, 14, 126)       504       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 14, 14, 126)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 126)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 126)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 148)         167980    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 148)         592       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7, 7, 148)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 148)         197284    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 148)         592       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 7, 7, 148)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 148)         197284    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 148)         592       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 7, 7, 148)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 148)         197284    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 7, 7, 148)         592       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 7, 7, 148)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 148)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 3, 3, 148)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1332)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1200)              1599600   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 1200)              4800      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1200)              1441200   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 1200)              4800      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               120100    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 4,217,824\n",
            "Trainable params: 4,211,032\n",
            "Non-trainable params: 6,792\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_QsjiULhEb5",
        "colab_type": "text"
      },
      "source": [
        "#### TRAIN THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMDA9J9399aJ",
        "colab_type": "code",
        "outputId": "8849a0d8-ce54-46b2-aa79-ab0393d53cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3607
        }
      },
      "source": [
        "# initiate RMSprop optimizer\n",
        "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_validation = x_validation.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "x_validation /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "    \n",
        "    validation_and_test_datagen = ImageDataGenerator()\n",
        "\n",
        "    \n",
        "        # Batch generators\n",
        "    train_generator = train_datagen.flow(\n",
        "        x_train, \n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    validation_generator = validation_and_test_datagen.flow(\n",
        "        x_validation, \n",
        "        y_validation, \n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    \n",
        "    \n",
        "        # this class is needed to adapt keras pipeline to shape modifications\n",
        "    class crop_gen(Sequence):\n",
        "\n",
        "        def __init__(self, gen):\n",
        "            self.gen = gen\n",
        "            self.x, self.y = next(gen)\n",
        "            self.batch_size = batch_size\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.gen.__len__()\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            batch_x, batch_y = next(self.gen)\n",
        "            batch_crops = np.zeros((batch_x.shape[0], input_size, input_size, 3))\n",
        "            for i in range(batch_x.shape[0]):\n",
        "                batch_crops[i] = random_crop(batch_x[i])\n",
        "            return batch_crops, batch_y\n",
        "\n",
        "    # this class is needed to adapt keras pipeline to shape modifications    \n",
        "    class crop_gen_center(Sequence):\n",
        "\n",
        "        def __init__(self, gen):\n",
        "            self.gen = gen\n",
        "            self.x, self.y = gen.__getitem__(0)\n",
        "            self.batch_size = batch_size\n",
        "            #self.classes = gen.classes\n",
        "            self.class_indices = np.arange(num_classes) #gen.class_indices\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.gen.__len__()\n",
        "\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            batch_x, batch_y = next(self.gen)\n",
        "            batch_crops = np.zeros((batch_x.shape[0], input_size, input_size, 3))\n",
        "            for i in range(batch_x.shape[0]):\n",
        "                batch_crops[i] = center_crop(batch_x[i])\n",
        "            return batch_crops, batch_y\n",
        "          \n",
        "    train_generator = crop_gen(train_generator)\n",
        "    validation_generator = crop_gen_center(validation_generator)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print('x_validation shape:', x_validation.shape)\n",
        "    history = model.fit_generator(\n",
        "      train_generator,\n",
        "      epochs=epochs,\n",
        "      shuffle=True,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps = len(x_validation)/batch_size,\n",
        "      steps_per_epoch = len(x_train)/batch_size,\n",
        "      workers=4\n",
        ")\n",
        "    \n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "\n",
        "X_test = np.zeros((np.shape(x_test)[0],input_size,input_size,3))\n",
        "\n",
        "for i in range(np.shape(x_test)[0]):\n",
        "  X_test[i] = center_crop(x_test[i])\n",
        "  \n",
        "  # Score trained model.\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "x_train shape: (40000, 32, 32, 3)\n",
            "x_validation shape: (10000, 32, 32, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 4.4212 - acc: 0.0636 - val_loss: 3.9010 - val_acc: 0.0992\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 3.8276 - acc: 0.1218 - val_loss: 3.4028 - val_acc: 0.1798\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 3.4719 - acc: 0.1687 - val_loss: 3.1718 - val_acc: 0.2110\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 3.2244 - acc: 0.2071 - val_loss: 3.0696 - val_acc: 0.2399\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 2.9920 - acc: 0.2492 - val_loss: 2.7200 - val_acc: 0.3079\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 2.8206 - acc: 0.2803 - val_loss: 2.7895 - val_acc: 0.2988\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 2.6782 - acc: 0.3090 - val_loss: 2.4313 - val_acc: 0.3722\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 2.5605 - acc: 0.3321 - val_loss: 2.4912 - val_acc: 0.3565\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 2.4918 - acc: 0.3484 - val_loss: 2.2475 - val_acc: 0.4075\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 2.3815 - acc: 0.3709 - val_loss: 2.1463 - val_acc: 0.4287\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 2.3270 - acc: 0.3848 - val_loss: 2.0168 - val_acc: 0.4612\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 2.2318 - acc: 0.4024 - val_loss: 2.2502 - val_acc: 0.4102\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 2.1841 - acc: 0.4167 - val_loss: 1.9236 - val_acc: 0.4827\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 2.1443 - acc: 0.4266 - val_loss: 2.0344 - val_acc: 0.4564\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 2.0792 - acc: 0.4372 - val_loss: 1.9338 - val_acc: 0.4769\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 2.0550 - acc: 0.4433 - val_loss: 2.0589 - val_acc: 0.4508\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 2.0068 - acc: 0.4543 - val_loss: 1.8503 - val_acc: 0.5006\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.9508 - acc: 0.4712 - val_loss: 1.7288 - val_acc: 0.5286\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.9121 - acc: 0.4790 - val_loss: 1.8793 - val_acc: 0.4889\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.9066 - acc: 0.4797 - val_loss: 1.7459 - val_acc: 0.5209\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.8546 - acc: 0.4898 - val_loss: 1.8659 - val_acc: 0.5016\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.8382 - acc: 0.4927 - val_loss: 1.7044 - val_acc: 0.5376\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 1.7975 - acc: 0.5052 - val_loss: 1.6270 - val_acc: 0.5560\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.7809 - acc: 0.5103 - val_loss: 1.7153 - val_acc: 0.5356\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.7860 - acc: 0.5102 - val_loss: 1.6608 - val_acc: 0.5457\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.7319 - acc: 0.5211 - val_loss: 1.6036 - val_acc: 0.5582\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.7397 - acc: 0.5213 - val_loss: 1.6961 - val_acc: 0.5469\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.7044 - acc: 0.5271 - val_loss: 1.6728 - val_acc: 0.5521\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.6736 - acc: 0.5321 - val_loss: 1.9930 - val_acc: 0.4937\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.6768 - acc: 0.5358 - val_loss: 1.6564 - val_acc: 0.5520\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.6224 - acc: 0.5473 - val_loss: 1.6858 - val_acc: 0.5450\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 1.6233 - acc: 0.5462 - val_loss: 1.6505 - val_acc: 0.5554\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.6121 - acc: 0.5528 - val_loss: 1.6146 - val_acc: 0.5655\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.5924 - acc: 0.5528 - val_loss: 1.6345 - val_acc: 0.5615\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.5644 - acc: 0.5601 - val_loss: 1.5649 - val_acc: 0.5740\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.5367 - acc: 0.5678 - val_loss: 1.5583 - val_acc: 0.5737\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.5313 - acc: 0.5729 - val_loss: 1.5332 - val_acc: 0.5773\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.6143 - acc: 0.5521 - val_loss: 1.6854 - val_acc: 0.5685\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.5145 - acc: 0.5737 - val_loss: 1.4778 - val_acc: 0.5951\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.4993 - acc: 0.5761 - val_loss: 1.4676 - val_acc: 0.6003\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.4949 - acc: 0.5792 - val_loss: 1.6173 - val_acc: 0.5774\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 1.4859 - acc: 0.5801 - val_loss: 1.4411 - val_acc: 0.5961\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.4935 - acc: 0.5804 - val_loss: 1.5473 - val_acc: 0.5880\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4432 - acc: 0.5923 - val_loss: 1.4833 - val_acc: 0.5948\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.4725 - acc: 0.5833 - val_loss: 1.5058 - val_acc: 0.5899\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.4178 - acc: 0.5974 - val_loss: 1.4768 - val_acc: 0.5966\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.4088 - acc: 0.5988 - val_loss: 1.6812 - val_acc: 0.5671\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.4398 - acc: 0.5923 - val_loss: 1.5840 - val_acc: 0.5877\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 1.3966 - acc: 0.6027 - val_loss: 1.4493 - val_acc: 0.6040\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.3818 - acc: 0.6047 - val_loss: 1.4963 - val_acc: 0.5824\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4290 - acc: 0.5960 - val_loss: 2.2451 - val_acc: 0.5331\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.4139 - acc: 0.6002 - val_loss: 1.5177 - val_acc: 0.5963\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.3685 - acc: 0.6062 - val_loss: 2.2384 - val_acc: 0.5322\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 1.3620 - acc: 0.6129 - val_loss: 1.8772 - val_acc: 0.5706\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.3579 - acc: 0.6117 - val_loss: 1.5205 - val_acc: 0.5830\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.3582 - acc: 0.6125 - val_loss: 1.4495 - val_acc: 0.6080\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.3435 - acc: 0.6139 - val_loss: 1.4399 - val_acc: 0.6060\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.3009 - acc: 0.6245 - val_loss: 1.4889 - val_acc: 0.6086\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.2995 - acc: 0.6267 - val_loss: 1.4264 - val_acc: 0.6227\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 1.2850 - acc: 0.6313 - val_loss: 1.5386 - val_acc: 0.5870\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.2868 - acc: 0.6290 - val_loss: 1.4794 - val_acc: 0.6106\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.3220 - acc: 0.6216 - val_loss: 1.5080 - val_acc: 0.6057\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.2732 - acc: 0.6315 - val_loss: 1.5581 - val_acc: 0.5964\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.2583 - acc: 0.6357 - val_loss: 1.3921 - val_acc: 0.6210\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.2876 - acc: 0.6270 - val_loss: 1.4537 - val_acc: 0.6056\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.3554 - acc: 0.6165 - val_loss: 1.4676 - val_acc: 0.6185\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.2782 - acc: 0.6293 - val_loss: 1.5041 - val_acc: 0.5920\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.2922 - acc: 0.6290 - val_loss: 1.4229 - val_acc: 0.6142\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.2508 - acc: 0.6388 - val_loss: 1.4704 - val_acc: 0.6112\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 33s 27ms/step - loss: 1.2866 - acc: 0.6294 - val_loss: 1.4926 - val_acc: 0.6104\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.3250 - acc: 0.6233 - val_loss: 1.4731 - val_acc: 0.6082\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.2507 - acc: 0.6345 - val_loss: 1.3793 - val_acc: 0.6226\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.2213 - acc: 0.6450 - val_loss: 1.5300 - val_acc: 0.6042\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.2271 - acc: 0.6464 - val_loss: 1.5265 - val_acc: 0.6163\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.2124 - acc: 0.6496 - val_loss: 1.5211 - val_acc: 0.6021\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.1794 - acc: 0.6577 - val_loss: 1.3934 - val_acc: 0.6256\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.2059 - acc: 0.6511 - val_loss: 2.2499 - val_acc: 0.5322\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.2781 - acc: 0.6346 - val_loss: 1.4390 - val_acc: 0.6247\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.2038 - acc: 0.6521 - val_loss: 1.4445 - val_acc: 0.6234\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 1.2682 - acc: 0.6349 - val_loss: 1.4184 - val_acc: 0.6252\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.2093 - acc: 0.6505 - val_loss: 1.4233 - val_acc: 0.6120\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.1749 - acc: 0.6579 - val_loss: 1.3861 - val_acc: 0.6312\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.2257 - acc: 0.6457 - val_loss: 1.4706 - val_acc: 0.6162\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.1896 - acc: 0.6550 - val_loss: 1.3412 - val_acc: 0.6282\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.1768 - acc: 0.6584 - val_loss: 1.4882 - val_acc: 0.6167\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.1753 - acc: 0.6595 - val_loss: 1.4657 - val_acc: 0.6308\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.1748 - acc: 0.6616 - val_loss: 1.4765 - val_acc: 0.6226\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.1828 - acc: 0.6573 - val_loss: 1.5564 - val_acc: 0.6086\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.1829 - acc: 0.6571 - val_loss: 1.4240 - val_acc: 0.6262\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.1377 - acc: 0.6662 - val_loss: 1.3789 - val_acc: 0.6240\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.1831 - acc: 0.6568 - val_loss: 1.4978 - val_acc: 0.6237\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.1224 - acc: 0.6704 - val_loss: 1.3909 - val_acc: 0.6251\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.1223 - acc: 0.6712 - val_loss: 1.4412 - val_acc: 0.6318\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.1226 - acc: 0.6702 - val_loss: 1.4965 - val_acc: 0.6261\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.1329 - acc: 0.6696 - val_loss: 1.5078 - val_acc: 0.6177\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.0908 - acc: 0.6789 - val_loss: 1.4201 - val_acc: 0.6266\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.1570 - acc: 0.6642 - val_loss: 1.4321 - val_acc: 0.6225\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.1085 - acc: 0.6737 - val_loss: 1.4202 - val_acc: 0.6304\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 1.0909 - acc: 0.6803 - val_loss: 1.3452 - val_acc: 0.6398\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 34s 27ms/step - loss: 1.0827 - acc: 0.6827 - val_loss: 1.3896 - val_acc: 0.6339\n",
            "Saved trained model at /content/saved_models/cifar_100_teacher.h5 \n",
            "10000/10000 [==============================] - 1s 145us/step\n",
            "Test loss: 1.4036770114898682\n",
            "Test accuracy: 0.6382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yjQKYHRhLqm",
        "colab_type": "text"
      },
      "source": [
        "#### PRINT ACCURACY OF THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjYyjMT61F93",
        "colab_type": "code",
        "outputId": "6e5d348a-315a-4388-db8c-daba9882ff9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_test = np.zeros((np.shape(x_test)[0],input_size,input_size,3))\n",
        "\n",
        "for i in range(np.shape(x_test)[0]):\n",
        "  X_test[i] = center_crop(x_test[i])\n",
        "  \n",
        "  # Score trained model.\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 145us/step\n",
            "Test loss: 1.4036770114898682\n",
            "Test accuracy: 0.6382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qBiH8QDhOOW",
        "colab_type": "text"
      },
      "source": [
        "#### PLOT THE MODEL ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIDTx3DECoj-",
        "colab_type": "code",
        "outputId": "0d99bb9b-7a8c-4298-a568-0013996e4ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "# list all data in historys\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}