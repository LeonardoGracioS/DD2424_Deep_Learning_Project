{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Student_models_1M_parameters.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re40KaWvVUoO",
        "colab_type": "text"
      },
      "source": [
        "# STUDENT MODELS WITH 1M PARAMETERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDgbC84YVbbx",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reivqlrUEnTE",
        "colab_type": "code",
        "outputId": "170b5b33-895a-4af2-809f-8bf5af5bd117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import Sequence\n",
        "from keras import regularizers\n",
        "from keras.models import load_model\n",
        "import os\n",
        "from keras.models import Model\n",
        "import h5py\n",
        "\n",
        "import time\n",
        "\n",
        "import colorsys #enables us to convert a rgb vector to a hsv vector\n",
        "from skimage.color import rgb2hsv, hsv2rgb\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqDKAOdmVeSf",
        "colab_type": "text"
      },
      "source": [
        "### Import Dataset : choose between CIFAR_10 and CIFAR_100\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVnjfFzLGmMQ",
        "colab_type": "code",
        "outputId": "055dcf37-1a48-4b52-ff85-2f392cc5a54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Loading the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "#(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "\n",
        "\n",
        "#Define the number of classes that you want to use\n",
        "\n",
        "num_classes = 10\n",
        "#num_classes = 100"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHFsB0eXWSJH",
        "colab_type": "text"
      },
      "source": [
        "## 1- Creation of the dataset using distillation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDdHyxQnXmTX",
        "outputId": "30fced08-6114-49cb-98d5-f764dc833e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "#Load the teacher model\n",
        "\n",
        "#teacher_model = load_model('keras_cifar10_trained_model2.h5')\n",
        "teacher_model = load_model('cifar_100_teacher-3.h5')\n",
        "\n",
        "#Get the layer just before the softmax layer\n",
        "without_softmax_model = Model(inputs=teacher_model.input, outputs=teacher_model.get_layer('dense_3').output)\n",
        "\n",
        "#Keep a copy of the original dataset before modifications\n",
        "x_train_bis = np.copy(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Uw0euOWxF_",
        "colab_type": "text"
      },
      "source": [
        "### Definitions of the different functions used in this ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibHSiEOT3jNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# random crop needed for training augmentation\n",
        "def random_crop(img):\n",
        "    height, width, _ = img.shape\n",
        "    dy, dx = input_size, input_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    img = img[y:(y+dy), x:(x+dx), :]\n",
        "    return img\n",
        "\n",
        "# center crop needed for testing (validation & test sets)\n",
        "def center_crop(img):\n",
        "    height, width, _ = img.shape\n",
        "    dy, dx = input_size, input_size\n",
        "    x = int((width - dx + 1)/2)\n",
        "    y = int((height - dy + 1)/2)\n",
        "    img = img[y:(y+dy), x:(x+dx), :]\n",
        "    return img\n",
        "  \n",
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    Compute softmax values for each sets of scores in x.\n",
        "    \n",
        "    Rows are scores for each class. \n",
        "    Columns are predictions (samples).\n",
        "    \"\"\"\n",
        "    scoreMatExp = np.exp(np.asarray(x))\n",
        "    return scoreMatExp / scoreMatExp.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czLu88umXqWg",
        "colab_type": "text"
      },
      "source": [
        "### Preparation of the data for Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4x04P7D-eVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "0b972a73-9ab6-4239-e95f-5d897bac167c"
      },
      "source": [
        "#Divide into training and validation set\n",
        "\n",
        "x_validation = x_train_bis[40000:]\n",
        "x_train_bis = x_train_bis[:40000]\n",
        "\n",
        "\n",
        "#Define input size for the data augmentation : we will keep input_size pixels after data augmentation\n",
        "input_size = 28\n",
        "\n",
        "### Cropping the images\n",
        "X_train = np.zeros((np.shape(x_train_bis)[0],input_size,input_size,3))\n",
        "\n",
        "#random crop for training set\n",
        "for i in range(np.shape(x_train_bis)[0]):\n",
        "  X_train[i] = random_crop(x_train_bis[i])\n",
        "  \n",
        "X_validation = np.zeros((np.shape(x_validation)[0],input_size,input_size,3))\n",
        "\n",
        "#center crop for validation set, no need for data augmentation, just input_size size images\n",
        "for i in range(np.shape(x_validation)[0]):\n",
        "  X_validation[i] = center_crop(x_validation[i])\n",
        "  \n",
        "### Normalizing the data\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "X_validation = X_validation.astype('float32')\n",
        "X_train /= 255\n",
        "x_test /= 255\n",
        "X_validation /= 255\n",
        "\n",
        "y_train_soft = without_softmax_model.predict(X_train, batch_size=32, verbose=0, steps=None)\n",
        "y_validation_soft = without_softmax_model.predict(X_validation, batch_size=32, verbose=0, steps=None)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "for i in range(len(y_train_soft)):\n",
        "  y_train_soft[i] = y_train_soft[i]/np.linalg.norm(y_train_soft[i])\n",
        "\n",
        "for i in range(len(y_validation_soft)):\n",
        "  y_validation_soft[i] = y_validation_soft[i]/np.linalg.norm(y_validation_soft[i])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0dbf17f28aea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_bis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_train_bis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_bis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train_bis' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN6J9cZf9FkT",
        "colab_type": "text"
      },
      "source": [
        "## 2- Creation of the student models with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zzyFIir3U8w",
        "colab_type": "text"
      },
      "source": [
        "### A- MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpXwTxyb6t0G",
        "colab_type": "text"
      },
      "source": [
        "#### One hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf8_97aj9Mn0",
        "colab_type": "code",
        "outputId": "024793c7-2912-4208-d98e-0884e6063228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(500, input_shape=(28*28*3,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 500)               1176500   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               50100     \n",
            "=================================================================\n",
            "Total params: 1,228,600\n",
            "Trainable params: 1,227,600\n",
            "Non-trainable params: 1,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXGPAtsP6vsx",
        "colab_type": "text"
      },
      "source": [
        "#### Two hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOYfItz06v0b",
        "colab_type": "code",
        "outputId": "759db5f9-5a8d-4704-ff4e-238a088a9ddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(500, input_shape=(28*28*3,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(200))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 500)               1176500   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 200)               100200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               20100     \n",
            "=================================================================\n",
            "Total params: 1,299,600\n",
            "Trainable params: 1,298,200\n",
            "Non-trainable params: 1,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdRUNV906v6y",
        "colab_type": "text"
      },
      "source": [
        "#### Tree hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Un08Dc6wAB",
        "colab_type": "code",
        "outputId": "89f58f7f-01ba-4068-f20a-a5b5b2e0a57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(400, input_shape=(28*28*3,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(300))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(200))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 400)               941200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 400)               1600      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 300)               120300    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 300)               1200      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               60200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               20100     \n",
            "=================================================================\n",
            "Total params: 1,145,400\n",
            "Trainable params: 1,143,600\n",
            "Non-trainable params: 1,800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wAJM_pw6wFD",
        "colab_type": "text"
      },
      "source": [
        "#### Four hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ndNSeDO6wKL",
        "colab_type": "code",
        "outputId": "464fc7e3-8e44-496d-de54-7a297a6fd7a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(400, input_shape=(28*28*3,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(350))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(200))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "model.add(Dense(100))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 400)               941200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 400)               1600      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 350)               140350    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 350)               1400      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               70200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               10100     \n",
            "=================================================================\n",
            "Total params: 1,186,150\n",
            "Trainable params: 1,184,050\n",
            "Non-trainable params: 2,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3kg3563W4l",
        "colab_type": "text"
      },
      "source": [
        "### B- CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwBTBt-13aWS",
        "colab_type": "text"
      },
      "source": [
        "#### One convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvJ8qyTb3bWS",
        "colab_type": "code",
        "outputId": "a964680b-a1f7-467a-9608-801eb8fa63dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(100, (3, 3), padding='same',\n",
        "                 input_shape=(28,28,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(75))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 100)       2800      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 100)       400       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 100)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 100)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 100)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 19600)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 75)                1470075   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 75)                300       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 75)                0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 75)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               7600      \n",
            "=================================================================\n",
            "Total params: 1,481,175\n",
            "Trainable params: 1,480,825\n",
            "Non-trainable params: 350\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm_aEKZq3bje",
        "colab_type": "text"
      },
      "source": [
        "#### Two convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI5hVmgA3bzq",
        "colab_type": "code",
        "outputId": "62f33d69-c413-49f7-95b5-8c941a75c5d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(100, (3, 3), padding='same',\n",
        "                 input_shape=(28,28,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(100, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 100)       2800      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 100)       400       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 100)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 100)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 100)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 100)       90100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 100)       400       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 100)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 100)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 100)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4900)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               1225250   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 250)               1000      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               25100     \n",
            "=================================================================\n",
            "Total params: 1,345,050\n",
            "Trainable params: 1,344,150\n",
            "Non-trainable params: 900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ramji5-M3cBi",
        "colab_type": "text"
      },
      "source": [
        "#### Three convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mxTWUOX3cLE",
        "colab_type": "code",
        "outputId": "f9d63ab6-5cd1-4b4e-8dc9-c6689f7369f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(100, (3, 3), padding='same',\n",
        "                 input_shape=(28,28,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(110, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(110, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 100)       2800      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 100)       400       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 100)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 100)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 110)       99110     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 110)       440       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 110)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 110)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 110)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 110)         109010    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 110)         440       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 110)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 110)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 110)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 990)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000)              991000    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               100100    \n",
            "=================================================================\n",
            "Total params: 1,307,300\n",
            "Trainable params: 1,304,660\n",
            "Non-trainable params: 2,640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JgMIJsi3cj7",
        "colab_type": "text"
      },
      "source": [
        "#### Four convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz_IYoaHx5CC",
        "colab_type": "code",
        "outputId": "155d1bca-8e68-4485-aa55-7b19c8203827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(75, (3, 3), padding='same',\n",
        "                 input_shape=(28,28,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(100, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(100, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(100, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1100))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 75)        2100      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 75)        300       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 75)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 75)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 75)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 100)       67600     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 100)       400       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 100)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 100)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 100)         90100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 100)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 100)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 3, 3, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 100)         90100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 3, 3, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 3, 3, 100)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 3, 100)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 900)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1100)              991100    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1100)              4400      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1100)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1100)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               110100    \n",
            "=================================================================\n",
            "Total params: 1,357,000\n",
            "Trainable params: 1,354,050\n",
            "Non-trainable params: 2,950\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rkl4GDn9Iin",
        "colab_type": "text"
      },
      "source": [
        "## 3- Training the chosen student model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9-GOzGKYuSl",
        "colab_type": "text"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDQdIrCc3d2b",
        "colab_type": "code",
        "outputId": "c610acf9-9010-4be5-a349-fd6c463ae5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1042
        }
      },
      "source": [
        "### Define parameters\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "data_augmentation = True #write False for a MLP and True for a CNN\n",
        "\n",
        "#opt = keras.optimizers.rmsprop(lr=0.1, decay=1e-6)\n",
        "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='mean_squared_error', metrics = ['mse'],\n",
        "              optimizer=opt)\n",
        "\n",
        "\n",
        "if data_augmentation == True:\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "          horizontal_flip=True  # randomly flip images\n",
        "  )\n",
        "\n",
        "  validation_and_test_datagen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "      # Batch generators\n",
        "  train_generator = train_datagen.flow(\n",
        "      X_train, \n",
        "      y_train_soft,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  validation_generator = validation_and_test_datagen.flow(\n",
        "      X_validation, \n",
        "      y_validation_soft, \n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "\n",
        "      # this class is needed to adapt keras pipeline to shape modifications\n",
        "  class crop_gen(Sequence):\n",
        "\n",
        "      def __init__(self, gen):\n",
        "          self.gen = gen\n",
        "          self.x, self.y = next(gen)\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "      def __len__(self):\n",
        "          return self.gen.__len__()\n",
        "\n",
        "      def __getitem__(self, idx):\n",
        "          batch_x, batch_y = next(self.gen)\n",
        "          batch_crops = np.zeros((batch_x.shape[0], input_size, input_size, 3))\n",
        "          for i in range(batch_x.shape[0]):\n",
        "              batch_crops[i] = random_crop(batch_x[i])\n",
        "          return batch_crops, batch_y\n",
        "\n",
        "  # this class is needed to adapt keras pipeline to shape modifications    \n",
        "  class crop_gen_center(Sequence):\n",
        "\n",
        "      def __init__(self, gen):\n",
        "          self.gen = gen\n",
        "          self.x, self.y = gen.__getitem__(0)\n",
        "          self.batch_size = batch_size\n",
        "          #self.classes = gen.classes\n",
        "          self.class_indices = np.arange(num_classes) #gen.class_indices\n",
        "\n",
        "      def __len__(self):\n",
        "          return self.gen.__len__()\n",
        "\n",
        "\n",
        "      def __getitem__(self, idx):\n",
        "          batch_x, batch_y = next(self.gen)\n",
        "          batch_crops = np.zeros((batch_x.shape[0], input_size, input_size, 3))\n",
        "          for i in range(batch_x.shape[0]):\n",
        "              batch_crops[i] = center_crop(batch_x[i])\n",
        "          return batch_crops, batch_y\n",
        "\n",
        "  #train_generator = crop_gen(train_generator)\n",
        "  #validation_generator = crop_gen_center(validation_generator)\n",
        "\n",
        "  # Fit the model on the batches generated by datagen.flow().\n",
        "  print('x_train shape:', X_train.shape)\n",
        "  print('x_validation shape:', X_validation.shape)\n",
        "  history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    shuffle=True,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps = len(X_validation)/batch_size,\n",
        "    steps_per_epoch = len(X_train)/batch_size,\n",
        "    workers=4\n",
        "  )\n",
        "else:\n",
        "  for i in range(len(X_train)):\n",
        "    if np.random.uniform(0,1) > 0.5:\n",
        "      X_train[i] = np.flip(X_train[i],axis=1)\n",
        "      \n",
        "  X_train = X_train.reshape(40000,28*28*3)\n",
        "  X_validation = X_validation.reshape(10000,28*28*3)\n",
        "\n",
        "  history = model.fit(X_train, y_train_soft,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      verbose=1,\n",
        "                      validation_data=(X_validation, y_validation_soft))\n",
        "    \n",
        "# Save model and weights\n",
        "#if not os.path.isdir(save_dir):\n",
        "#    os.makedirs(save_dir)\n",
        "#model_path = os.path.join(save_dir, model_name)\n",
        "#model.save(model_path)\n",
        "#print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "\n",
        "X_test = np.zeros((np.shape(x_test)[0],input_size,input_size,3))\n",
        "\n",
        "for i in range(np.shape(x_test)[0]):\n",
        "  X_test[i] = center_crop(x_test[i])\n",
        "  \n",
        "if data_augmentation==False:\n",
        "  X_test = X_test.reshape(10000,28*28*3)\n",
        "  \n",
        "  # Score trained model.\n",
        "scores = model.evaluate(X_test, y_test_cat, verbose=1)\n",
        "print('Test loss:', scores)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "acc = 0\n",
        "softmax_predictions = np.zeros((num_classes,10000))\n",
        "for i in range(np.shape(X_test)[0]):\n",
        "  softmax_predictions[:,i] = softmax(predictions[i,:])\n",
        "  if np.argmax(softmax_predictions[:,i])==y_test[i]:\n",
        "    acc = acc + 1\n",
        "acc = acc/10000\n",
        "\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (40000, 28, 28, 3)\n",
            "x_validation shape: (10000, 28, 28, 3)\n",
            "Epoch 1/28\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.0646 - mean_squared_error: 0.0646 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2/28\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 6.2321e-04 - val_mean_squared_error: 6.2321e-04\n",
            "Epoch 3/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 6.7435e-04 - mean_squared_error: 6.7435e-04 - val_loss: 5.8773e-04 - val_mean_squared_error: 5.8773e-04\n",
            "Epoch 4/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 6.1124e-04 - mean_squared_error: 6.1124e-04 - val_loss: 5.6559e-04 - val_mean_squared_error: 5.6559e-04\n",
            "Epoch 5/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 5.8174e-04 - mean_squared_error: 5.8174e-04 - val_loss: 5.3863e-04 - val_mean_squared_error: 5.3863e-04\n",
            "Epoch 6/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 5.4977e-04 - mean_squared_error: 5.4977e-04 - val_loss: 5.2597e-04 - val_mean_squared_error: 5.2597e-04\n",
            "Epoch 7/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 5.1632e-04 - mean_squared_error: 5.1632e-04 - val_loss: 5.7672e-04 - val_mean_squared_error: 5.7672e-04\n",
            "Epoch 8/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 4.7860e-04 - mean_squared_error: 4.7860e-04 - val_loss: 4.8651e-04 - val_mean_squared_error: 4.8651e-04\n",
            "Epoch 9/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 4.5149e-04 - mean_squared_error: 4.5149e-04 - val_loss: 3.9809e-04 - val_mean_squared_error: 3.9809e-04\n",
            "Epoch 10/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 4.4387e-04 - mean_squared_error: 4.4387e-04 - val_loss: 3.8945e-04 - val_mean_squared_error: 3.8945e-04\n",
            "Epoch 11/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 4.2285e-04 - mean_squared_error: 4.2285e-04 - val_loss: 3.8246e-04 - val_mean_squared_error: 3.8246e-04\n",
            "Epoch 12/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 4.0459e-04 - mean_squared_error: 4.0459e-04 - val_loss: 4.0202e-04 - val_mean_squared_error: 4.0202e-04\n",
            "Epoch 13/28\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 3.9116e-04 - mean_squared_error: 3.9116e-04 - val_loss: 3.5242e-04 - val_mean_squared_error: 3.5242e-04\n",
            "Epoch 14/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.7952e-04 - mean_squared_error: 3.7952e-04 - val_loss: 3.5351e-04 - val_mean_squared_error: 3.5351e-04\n",
            "Epoch 15/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.6909e-04 - mean_squared_error: 3.6909e-04 - val_loss: 3.1501e-04 - val_mean_squared_error: 3.1501e-04\n",
            "Epoch 16/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.5947e-04 - mean_squared_error: 3.5947e-04 - val_loss: 3.6455e-04 - val_mean_squared_error: 3.6455e-04\n",
            "Epoch 17/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.5250e-04 - mean_squared_error: 3.5250e-04 - val_loss: 3.1097e-04 - val_mean_squared_error: 3.1097e-04\n",
            "Epoch 18/28\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 3.4505e-04 - mean_squared_error: 3.4505e-04 - val_loss: 3.4387e-04 - val_mean_squared_error: 3.4387e-04\n",
            "Epoch 19/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.3817e-04 - mean_squared_error: 3.3817e-04 - val_loss: 4.0377e-04 - val_mean_squared_error: 4.0377e-04\n",
            "Epoch 20/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.3291e-04 - mean_squared_error: 3.3291e-04 - val_loss: 3.3408e-04 - val_mean_squared_error: 3.3408e-04\n",
            "Epoch 21/28\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 3.2809e-04 - mean_squared_error: 3.2809e-04 - val_loss: 2.7883e-04 - val_mean_squared_error: 2.7883e-04\n",
            "Epoch 22/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.2481e-04 - mean_squared_error: 3.2481e-04 - val_loss: 4.3629e-04 - val_mean_squared_error: 4.3629e-04\n",
            "Epoch 23/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.2239e-04 - mean_squared_error: 3.2239e-04 - val_loss: 2.9637e-04 - val_mean_squared_error: 2.9637e-04\n",
            "Epoch 24/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.4126e-04 - mean_squared_error: 3.4126e-04 - val_loss: 3.2260e-04 - val_mean_squared_error: 3.2260e-04\n",
            "Epoch 25/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.1708e-04 - mean_squared_error: 3.1708e-04 - val_loss: 2.9327e-04 - val_mean_squared_error: 2.9327e-04\n",
            "Epoch 26/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.1371e-04 - mean_squared_error: 3.1371e-04 - val_loss: 3.3876e-04 - val_mean_squared_error: 3.3876e-04\n",
            "Epoch 27/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 3.0958e-04 - mean_squared_error: 3.0958e-04 - val_loss: 3.3114e-04 - val_mean_squared_error: 3.3114e-04\n",
            "Epoch 28/28\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 5.7204e-04 - mean_squared_error: 5.7204e-04 - val_loss: 5.3611e-04 - val_mean_squared_error: 5.3611e-04\n",
            "10000/10000 [==============================] - 1s 86us/step\n",
            "Test loss: [0.021132344365119935, 0.021132344365119935]\n",
            "Test accuracy: 0.0319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agp-aCJaYl21",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the loss curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIDTx3DECoj-",
        "colab_type": "code",
        "outputId": "87cef2ee-f82e-43c8-bfe1-645c51de8c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# list all data in historys\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_mean_squared_error', 'loss', 'mean_squared_error'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}